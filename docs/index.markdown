---

layout: default
---


The recent surge in the number of publicly available neural network models—exceeding a million on platforms like Hugging Face—calls for a shift in how we perceive neural network weights. This workshop aims to establish neural network weights as a new data modality, offering immense potential across various fields.

We plan to address key dimensions of **weight space learning:**

- **Weight Space as a Modality**: Characterization of the weight space, <br> symmetries, scaling laws, and model zoo datasets.
- **Model analysis**: Inferring model properties, such as test performance <br> or generalization error, by the inspection of their weights.
- **Model synthesis**: Generating model weights for specific datasets and tasks, <br> and improving tasks like pruning, merging, and robustness through weight manipulation.
- **Learning from populations**: Using data from neural network populations to identify <br> and exploit structure in trained models.
- **Applications to neural fields and beyond**: Applying weight space learning to 3D shape analysis, neural radiance fields (NeRFs), and other domains.

Weight space learning remains a nascent and scattered research area. Our goal is to provide a bridge between the abovementioned topics, and research areas such as model merging, neural architecture search, and meta-learning. By aligning terminology and methodologies, we aim to drive sustained progress and foster interdisciplinary collaboration.

## Research Goals and Key Questions

This workshop will explore fundamental questions about weight spaces, such as:

- What properties of weights, such as symmetries and invariances, present challenges or can be leveraged for optimization, learning and generalization?
- How can model weights be efficiently represented, manipulated, and used for downstream tasks?
- What model information can be decoded from model weights?
- Can model weights be generated for specific applications, to make training and model selection more efficient?
- Can weight space learning benefit research in processing and synthesising neural fields, for e.g. scientific applications and 3D vision?
- How can we democratize the usage of weight spaces, enabling more efficient research progress?

## Tentative Schedule

| Time      | Duration | Session Content                                   |
| --------- | -------- | ------------------------------------------------- |
| 9:00 AM   | 30 min   | Introduction and opening remarks                  |
| 9:30 AM   | 60 min   | Opening Keynote                                   |
| 10:30 AM  | 30 min   | Coffee Break                                      |
| 11:00 AM  | 15 min   | Session 1: Graphs and Symmetries                  |
| 11:15 AM  | 30 min   | Invited Talk + Q&A                                |
| 11:45 AM  | 30 min   | 2x Spotlight Talks (each 15 min)                  |
| 12:15 PM  | 75 min   | Lunch Break                                       |
| 1:30 PM   | 15 min   | Session 2: Representation Learning                |
| 1:45 PM   | 30 min   | Invited Talk + Q&A                                |
| 2:15 PM   | 30 min   | 2x Spotlight Talks (each 15 min)                  |
| 2:45 PM   | 75 min   | Coffee Break + Poster Session                     |
| 4:00 PM   | 15 min   | Session 3: Downstream Applications                |
| 4:15 PM   | 30 min   | Invited Talk + Q&A                                |
| 4:45 PM   | 15 min   | Closing Remarks                                   |

## Accessibility and Modality

All accepted papers and posters will be available online for remote attendees. The talks will be recorded and made available on YouTube. We will also have a dedicated Discord channel for virtual engagement, ensuring that participants, whether in-person or remote, can collaborate and discuss ideas.

<!-- ## Invited Speakers

We are honored to have several leading experts who will provide keynote presentations. Each speaker brings unique insights into machine learning theory, weight space analysis, and neural network synthesis. Full list will be available at a later date.

**Chelsea Finn** (Stanford University)
- **Michael Mahoney** (UC Berkeley)
- **Stella Yu** (University of Michigan)
- **Boris Knyazev** (Samsung SAIT AI Lab)
- **Naomi Saphra** (Harvard University)-->

<!-- ## Organizing Committee

- **Konstantin Schürholt** (University of St. Gallen)
- **Giorgos Bouritsas** (Archimedes AI & University of Athens).
- **Eliahu Horwitz** (HUJI)
- **Derek Lim** (MIT & Liquid AI)
- **Yoav Gelberg** (University of Oxford)
- **Bo Zhao** (University of California, San Diego)
- **Allan Zhou** (Google Deepmind)
- **Damian Borth** (HSG, UW & TU/e)
- **Stefanie Jegelka** (MIT & TU Munich) 
-->


## Submission and Important Dates

- **Submission Deadline**: February 3, 2025
- **Author Notification**: March 5, 2025
- **Camera-Ready Deadline**: March 26, 2025
- **Workshop Day**: April 27 or 28, 2025

