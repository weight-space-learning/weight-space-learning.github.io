---
layout: default
title: Accepted Papers
---

## Spotlights

| Title | Authors                                                                                                                 | Paper                       |
|-------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|----------------------------------|
|                                                                                                       |                                                                                                                         |                                 |
|                                                                                                       |                                                                                                                         |                                 |
| Adversarial Robustness in Parameter-Space Classifiers                                                 | Tamir Shor, Ethan Fetaya, Chaim Baskin, Alex M. Bronstein                                                               | [arxiv](https://arxiv.org/abs/2502.20314)|
| Equivariant Neural Functional Networks for Transformers                                              | Hoang V. Tran, Thieu Vo, An Nguyen The, Tho Tran Huu, Minh-Khoi Nguyen-Nhat, Thanh Tran, Duy-Tung Pham, Tan Minh Nguyen |                                 |
| Adiabatic Fine-Tuning of Neural Quantum States Enables Detection of Phase Transitions in Weight Space | Vinicius Hernandes, Thomas Spriggs, Saqar Khaleefah, Eliska Greplova                                                    | [arxiv](https://arxiv.org/abs/2503.17140)|
<!-- | Model Diffusion for Certifiable Few-shot Transfer Learning                                           | Fady Rezk, Royson Lee, Henry Gouk, Timothy Hospedales, Minyoung Kim                                                     | [pdf](https://github.com/weight-space-learning/weight-space-learning.github.io/blob/main/docs/assets/STEEL.pdf)                                | -->
| Integrating Meta-Trained Hypernetworks with GBDTs and Retrieval for Tabular Data                      | David Bonet, Marçal Comajoan Cara, Alvaro Calafell, Daniel Mas Montserrat, Alexander G. Ioannidis                       |                                 |


## Posters

| Title                                                                                                 | Authors                                                                                                                 | Paper                       |
|-------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|----------------------------------|
|                                                                                                                    |                                                                                                     |                                  |
| Text-to-Model: Text-Conditioned Neural Network Diffusion for Train-Once-for-All Personalization                    | Zexi Li, Lingzhi Gao, Chao Wu                                                                       | [arxiv](https://arxiv.org/abs/2405.14132) |
| A Single Global Merging Suffices: Recovering Centralized Learning  Performance in Decentralized Learning           | Tongtian Zhu, Tianyu Zhang, Mingze Wang, Zhanpeng Zhou, Can Wang                                    |                                  |
| TeleLoRA: Teleporting Alignment across Large Language Models for Trojan Mitigation                                 | Xiao Lin, Manoj Acharya, Anirban Roy, Susmit Jha                                                    | [arxiv](https://arxiv.org/abs/2503.20228)  |
| Dataset Size Recovery from Fine-Tuned Model Weights                                                                | Mohammad Salama, Jonathan Kahana, Eliahu Horwitz, Yedid Hoshen                                      | [arxiv](https://arxiv.org/abs/2406.19395) |
| Finding Stable Subnetworks at Initialization with Dataset Distillation                                             | Luke McDermott, Rahul Parhi                                                                         | [arxiv](https://arxiv.org/abs/2503.17905) |
| Collaborative Time Series Imputation through Meta-learned Implicit Neural Representations                          | Tong Nie, Wei Ma                                                                                    |                                  |
| Fusion of Graph Neural Networks via Optimal Transport                                                              | Weronika Ormaniec, Michael Vollenweider, Elisa Hoskovec                                             | [arxiv](https://arxiv.org/abs/2503.21579) |
| Recursive Self-Similarity in Deep Weight Spaces of Neural Architectures: A Fractal and Coarse Geometry Perspective | Ambarish Moharil, Indika Kumara, Majid Mohammadi, Damian Andrew Tamburri, Willem-Jan van den Heuvel | [arxiv](https://arxiv.org/abs/2503.14298) |
| Instruction-Guided Autoregressive Neural Network Parameter Generation                                              | Bedionita Soro, Bruno Andreis, Song Chong, Sung Ju Hwang                                            | [arxiv](https://arxiv.org/abs/2504.02012) |
| The Space Between: On Folding, Symmetries and Sampling                                                             | Michal Lewandowski, Bernhard Heinzl, Raphael Pisoni, Bernhard A. Moser                              | [arxiv](https://arxiv.org/abs/2503.08502) |
| Cost-Efficient Continual Learning with Sufficient Exemplar Memory                                                  | Dong Kyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha                                 | [arxiv](https://arxiv.org/abs/2502.07274) |
| ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction                       | Tong Zhou, Shijin Duan, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu   | [arxiv](https://arxiv.org/abs/2503.13224) |
| Shape Generation via Weight Space Learning                                                                         | Maximilian Plattner, Arturs Berzins, Johannes Brandstetter                                          | [arxiv](https://arxiv.org/abs/2503.21830) |
| Mimetic Initialization Helps State Space Models Learn to Recall                                                    | Asher Trockman, Hrayr Harutyunyan, J Zico Kolter, Sanjiv Kumar, Srinadh Bhojanapalli                |                                  |
| Scaling Up Parameter Generation: A Recurrent Diffusion Approach                                                    | Kai Wang, Dongwen Tang, Wangbo Zhao, Konstantin Schürholt, Zhangyang Wang, Yang You                 | [arxiv](https://arxiv.org/abs/2501.11587) |
| Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces                                               | Yihuai Hong, Lei Yu, Haiqin Yang, Shauli Ravfogel, Mor Geva                                         |                                  |
| Learning on Model Weights using Tree Experts                                                                       | Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen                                            | [arxiv](https://arxiv.org/abs/2410.13569) |
| Uncovering Latent Chain of Thought Vectors in Large Language Models                                                | Jason Zhang, Scott W Viteri                                                                         | [arxiv](https://arxiv.org/abs/2409.14026) |
| GradMetaNet: An Equivariant Architecture for Learning on Gradients                                                 | Yoav Gelberg, Yam Eitan, Aviv Navon, Aviv Shamsian, Theo Putterman, Haggai Maron                    |                                  |
| Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights                                            | Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen                                            | [arxiv](https://arxiv.org/abs/2502.09619) |
| Structure Is Not Enough: Leveraging Behavior for Neural Network Weight Reconstruction                              | Léo Meynent, Ivan Melev, Konstantin Schürholt, Goeran Kauermann, Damian Borth                       | [arxiv](https://arxiv.org/abs/2503.17138) |
| Can We Optimize Deep RL Policy Weights as Trajectory Modeling?                                                     | Hongyao Tang                                                                                        | [arxiv](https://arxiv.org/abs/2503.04074) |
| A Model Zoo of Vision Transformers                                                                                 | Damian Falk, Léo Meynent, Florence Pfammatter, Konstantin Schürholt, Damian Borth                   |                                  |
| Unveiling the Potential of Superexpressive Networks in Implicit Neural Representations                             | Uvini Balasuriya Mudiyanselage, Woojin Cho, Minju Jo, Noseong Park, Kookjin Lee                     | [arxiv](https://arxiv.org/abs/2503.21166) |
| A Model Zoo on Phase Transitions in Neural Networks                                                                | Konstantin Schürholt, Léo Meynent, Yefan Zhou, Yaoqing Yang, Damian Borth                           |                                  |
| The Impact of Model Zoo Size and Composition on Weight Space Learning                                              | Damian Falk, Konstantin Schürholt, Damian Borth                                                     |                                  |
| Vanishing Feature: Diagnosing Model Merging and Beyond                                                             | Xingyu Qu, Samuel Horváth                                                                           | [arxiv](https://arxiv.org/abs/2402.05966) | 
| End-to-End Synthesis of Neural Programs in Weight Space                                                            | Wenhao Li, Yudong Xu, Elias Boutros Khalil, Scott Sanner                                            |                                  |
| The Empirical Impact of Reducing Symmetries on the Performance of Deep Ensembles and MoE                           | Andrei Chernov, Oleg Novitskij                                                                      | [arxiv](https://arxiv.org/abs/2502.17391) |
| ARC: Anchored Representation Clouds for High-Resolution INR Classification                                         | Joost Luijmes, Alexander Gielisse, Roman Knyazhitskiy, Jan van Gemert                               | [arxiv](https://arxiv.org/abs/2503.15156) |
| Learning on LoRAs: GL-Equivariant Processing of Low-Rank Weight Spaces for Large Finetuned Models                  | Theo Putterman, Derek Lim, Yoav Gelberg, Stefanie Jegelka, Haggai Maron                             |                                  |
| Mimetic Initialization of MLPs                                                                                     | Asher Trockman, J Zico Kolter                                                                       |                                  |
| Improving Learning to Optimize Using Parameter Symmetries                                                          | Guy Zamir, Aryan Dokania, Bo Zhao, Rose Yu                                                          |  [arxiv](https://arxiv.org/abs/2504.15399)                                |
| Flow to Learn: Flow Matching on Neural Network Parameters                                                          | Daniel Saragih, Deyu Cao, Tejas Balaji, Ashwin Santhosh                                             | [arxiv](https://arxiv.org/abs/2503.19371) |
| On the internal representations of graph metanetworks                                                              | Taesun Yeom, Jaeho Lee                                                                              | [arxiv](https://arxiv.org/abs/2503.09120) |
| Compressive Meta-Learning                                                                                          | Daniel Mas Montserrat, David Bonet, Maria Perera, Xavier Giró-i-Nieto, Alexander G. Ioannidis       |                                  |
| Model Assembly Learning with Heterogeneous Layer Weight Merging                                                    | Yi-Kai Zhang, Jin Wang, Xu-Xiang Zhong, De-Chuan Zhan, Han-Jia Ye                                   | [arxiv](https://arxiv.org/abs/2503.21657) |
| GNNMERGE: MERGING OF GNN MODELS WITHOUT ACCESSING TRAINING DATA                                                    | Vipul Garg, Ishita Thakre, Sayan Ranu                                                               | [arxiv](https://arxiv.org/abs/2503.03384) |
| On Symmetries in Convolutional Weights                                                                             | Bilal Alsallakh, Timothy J Wroge, Vivek Miglani, Narine Kokhlikyan                                  | [arxiv](https://arxiv.org/abs/2503.19215) |
| Hyper-Align: Efficient Modality Alignment via Hypernetworks                                                        | Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto                                        |                                  |